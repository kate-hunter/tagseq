#From https://wiki.chpc.utah.edu/display/~u0424091/Snakemake
#dry run: snakemake -n -s snakefile

#rule stock:
#    input:
#    output:
#    resources:mem_mb=lambda wildcards,  attempt: (1000*attempt)
#    params:cpu=1
#    shell:"""
#

###USER INPUT####
project_path="/uufs/chpc.utah.edu/common/home/kapheim-group2/nmel_immune_tagseq/"
reads_path="/uufs/chpc.utah.edu/common/home/kapheim-group2/nmel_immune_tagseq/kate_practice/nmel_tagseq/fastq_files/GSAF_files_prac/"
#snake_scripts_path="/uufs/chpc.utah.edu/common/home/kapheim-group2/nmel_immune_tagseq/kate_practice/nmel_tagseq/scripts/snake/khprac/"
#perl_path="/uufs/chpc.utah.edu/common/home/kapheim-group2/nmel_immune_tagseq/kate_practice/nmel_tagseq/scripts/perl_scripts/"
genome="/uufs/chpc.utah.edu/common/home/kapheim-group2/nmel_immune_tagseq/kate_practice/nmel_tagseq/genome/"
fasta_file="/uufs/chpc.utah.edu/common/home/kapheim-group2/nmel_immune_tagseq/kate_practice/nmel_tagseq/genome/genome_files/NMEL_genome_v2.1.0.fasta"
gff_file="/uufs/chpc.utah.edu/common/home/kapheim-group2/nmel_immune_tagseq/kate_practice/nmel_tagseq/genome/genome_files/NMEL_OGS_v2.1.0.gff3"
rscripts="/uufs/chpc.utah.edu/common/home/kapheim-group2/nmel_immune_tagseq/kate_practice/nmel_tagseq/scripts/snake/khprac/Rstuff/"
#####End INPUT###


ids, =glob_wildcards(reads_path+"{id}_L099_R1_cmb.trim.fastq.gz")

rule all:
        input:expand(reads_path+"{sample}_L099_R1_cmb.trim.fastq.gz", sample=ids),
              expand(reads_path+"unzipped/"+"{sample}.trim.fastq", sample=ids),
              genome+"index_done.txt",
              expand(reads_path+"SAM/{sample}/"+"{sample}_Aligned.out.sam", sample=ids),
              expand(reads_path+"BAM/{sample}/"+"{sample}_Aligned.sortedByCoord.out.bam", sample=ids),
              #expand(reads_path+"htseq/strandedisreverse/{sample}.txt", sample=ids),
              #reads_path+"htseq/matrix.csv"

# Say you have a .fastq.gz file named <sample_name>.fastq.gz for each sample
# in the list ids. This rule will run unzip_files for
# each of those .fastq.gz files:

rule unzip_files:
        input: reads_path+"{sample}_L099_R1_cmb.trim.fastq.gz"
        output: reads_path+"unzipped/"+"{sample}.trim.fastq"
        resources: mem_mb=lambda wildcards,  attempt: (1000*attempt)
        params: cpu=1,
                id="{sample}",
                input_path=reads_path
        shell:"""
              cd {params.input_path}
              zcat {input} > {output}
              """

# The sjdbOverhang is 99 here because some seem to just stick with the defaults
# the attempt change to 40,0000 x attempt, because by default STAR uses it's 31G
# Based on Tim's advice, upping CPUs to 6 and upping the threads (where every CPU=2threads/cores)
rule genome_index:
        input: fasta_file
        output: genome+"index_done.txt"
        resources: mem_mb=lambda wildcards,  attempt: (40000*attempt)
        params: cpu=6,
                fasta=fasta_file,
                gff=gff_file,
                output_indexdirec=genome+"indexing"
        shell:"""
              module load star
              STAR --runThreadN 12 \
              --runMode genomeGenerate \
              --genomeDir {params.output_indexdirec} \
              --genomeFastaFiles {params.fasta} \
              --sjdbGTFfile {params.gff} \
              --sjdbGTFtagExonParentTranscript Parent \
              --sjdbOverhang 99
              touch {output}
              """


rule align_reads:
        input: reads_path+"unzipped/"+"{sample}.trim.fastq"
        output: reads_path+"SAM/{sample}/"+"{sample}_Aligned.out.sam"
        resources: mem_mb=lambda wildcards,  attempt: (40000*attempt)
        params: cpu=6,
                id="{sample}",
                indexdirec=genome+"indexing",
                folder_loca=reads_path+"SAM/{sample}/{sample}_"
        shell:"""
              module load star
              STAR --runThreadN 12 \
              --runMode alignReads \
              --genomeDir {params.indexdirec} \
              --outSAMtype SAM \
              --readFilesIn {input} \
              --outFileNamePrefix {params.folder_loca}
              """

rule align_reads_BAM:
        input: reads_path+"unzipped/"+"{sample}.trim.fastq"
        output: reads_path+"BAM/{sample}/"+"{sample}_Aligned.sortedByCoord.out.bam"
        resources: mem_mb=lambda wildcards,  attempt: (40000*attempt)
        params: cpu=6,
                id="{sample}",
                indexdirec=genome+"indexing",
                folder_loca=reads_path+"BAM/{sample}/{sample}_"
        shell:"""
              module load star
              STAR --runThreadN 12 \
              --runMode alignReads \
              --genomeDir {params.indexdirec} \
              --outSAMtype BAM SortedByCoordinate \
              --outSAMunmapped Within \
              --readFilesIn {input} \
              --outFileNamePrefix {params.folder_loca}\
              --outSAMattributes Standard
              """


# rule qualimap:
#         input:
#         output:
#         resources: mem_mb=lambda wildcards,  attempt: (1000*attempt)
#         params: cpu=1
#         shell:"""
#               """

#the parameters for the counting rule
# -s should be yes (default, but I included it here) because Tagseq is strand-specific
# -m should be union because the read can then overlap more than one feature
# -t exon because the utr is getting transcribed.
# -i Parent because that's what the the attribute is called in gff
#https://www.embopress.org/doi/full/10.15252/msb.20209539
# above is the code that helped me decide what to do in relation to htseq
rule counting:
        input: sam = reads_path+"SAM/{sample}/"+"{sample}_Aligned.out.sam"
        output: reads_path+"htseq/strandedisreverse/{sample}.txt"
        resources: mem_mb=lambda wildcards,  attempt: (1000*attempt)
        params: cpu=1,
                gff=gff_file,
                id="{sample}"
        shell:"""
              module load python/3.6.3
              python -m HTSeq.scripts.count \
              -m union \
              -s reverse \
              -t mRNA \
              -i Parent \
              {input} {params.gff} > {output}
              """

rule combine_matrices:
        input: reads_path+"htseq/"
        output: reads_path+"htseq/matrix.csv"
        resources: mem_mb=lambda wildcards,  attempt: (1000*attempt)
        params: cpu=1,
                concat_script=rscripts+"htseq_scriptconcat.R"
        shell:"""
              cd {input}
              module load R
              Rscript {params.concat_script}
              """
