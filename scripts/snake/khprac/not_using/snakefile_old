#From https://wiki.chpc.utah.edu/display/~u0424091/Snakemake
#dry run: snakemake -n -s snakefile

#rule stock:
#    input:
#    output:
#    resources:mem_mb=lambda wildcards,  attempt: (1000*attempt)
#    params:cpu=1
#    shell:"""
#

###USER INPUT####
project_path="/uufs/chpc.utah.edu/common/home/kapheim-group2/nmel_immune_tagseq/"
reads_path="/uufs/chpc.utah.edu/common/home/kapheim-group2/nmel_immune_tagseq/fastq_files"
snake_scripts_path="/uufs/chpc.utah.edu/common/home/kapheim-group2/nmel_immune_tagseq/kate_practice/nmel_tagseq/scripts/snake/khprac/"
perl_path="/uufs/chpc.utah.edu/common/home/kapheim-group2/nmel_immune_tagseq/kate_practice/nmel_tagseq/scripts/perl_scripts/"
genome="/uufs/chpc.utah.edu/common/home/kapheim-group2/nmel_immune_tagseq/kate_practice/nmel_tagseq/genome/"
#####End INPUT###

(ids)=glob_wildcards(reads_path+"{id}_S***_L099_R1_cmb.trim.fastq.gz")

rule all:
        input:expand
              #expand(project_path+"unzipped/"+"{sample}_L00{lane}_R1_001.fastq", sample=ids, lane=lanes),
              #expand(project_path+"concatenated/"+"{sample}.fastq", sample=ids),
              #expand(project_path+"clipped_tags/"+"{sample}_clip.fastq", sample=ids),
              #expand(project_path+"clipped_tags/summaries/"+"{sample}.fastq.summary.txt", sample=ids),
              #expand(project_path+"clipped_tags/summaries/summaries.txt")

#above rule changed because the GSAF freely trimmed/clipped reads.

# Say you have a .fastq.gz file named <sample_name>.fastq.gz for each sample
# in the list ids. This rule will run unzip_files for
# each of those .fastq.gz files:

rule unzip_files:
        input: project_path+"original_files/"+"{sample}_L00{lane}_R1_001.fastq.gz"
        output: project_path+"unzipped/"+"{sample}_L00{lane}_R1_001.fastq"
        resources: mem_mb=lambda wildcards,  attempt: (1000*attempt)
        params: cpu=1,
                id="{sample}",
                lane="{lane}",
                input_path=project_path+"original_files/"
        shell:"""
              cd {params.input_path}
              zcat {input} > {output}
              """

#concatenating files here, make sure to check using wc -l that the concatenated files are the same line count a
#as the individual files

rule concatenate_files_cat:
        input:
              l1=project_path+"unzipped/"+"{sample}_L001_R1_001.fastq",
              l2=project_path+"unzipped/"+"{sample}_L002_R1_001.fastq"
        output: project_path+"concatenated/"+"{sample}.fastq"
        params: cpu=1
        resources: mem_mb=lambda wildcards,  attempt: (1000*attempt)
        shell:"""
 			  cat {input.l1} {input.l2}> {output}
 			  """

#clips 5' leader and removes duplicated sequences from reads based on whether
#there is an N in the first 20 bases of the sequence

#shortcut to comment out code is command and /
#Need a rule here to run through tagseq_clipper then because of this link I realized that I needed cutadapt:
#https://github.com/z0on/tag-based_RNAseq/blob/master/tagSeq_processing_README.txt
# rule trim_seq_fil:
#        input: project_path+"concatenated/"+"{sample}.fastq"
#        output: project_path+"clipped_tags/"+"{sample}.fastq.trim"
#        resources: mem_mb=lambda wildcards,  attempt: (1000*attempt)
#        params:cpu=1,
#               map=perl_path+"tagseq_clipper.pl",
#               seqs=project_path+"concatenated/"+"{sample}.fastq"
#        shell:"""
#              module load perl
#              module load cutadapt
#              perl {params.map} {params.seqs} |\
#              cutadapt - -a AAAAAAAA -a AGATCGG \
#              -q 15 -m 25 -o" > {output}
# 			  """

#Below rule is to use specifically the tagseq_clipper tool. above rule for trim_seq_fill is the
#correct rule to run the clipper and quality filter
rule clip_5pldr_dups:
        input: project_path+"concatenated/"+"{sample}.fastq"
        output:
               clips=project_path+"clipped_tags/"+"{sample}_clip.fastq",
               summaries=project_path+"concatenated/"+"{sample}.fastq.summary.txt"
        resources: mem_mb=lambda wildcards,  attempt: (1000*attempt)
        params:cpu=1,
               map=perl_path+"tagseq_clipper.pl",
               seqs=project_path+"concatenated/"+"{sample}.fastq"
        shell:"""
              module load perl
              perl {params.map} {input} > {output.clips}
			  """

#Below rule is to copy the summaries of the tagseq_clipper tool into a different folder, might not need
# rule move_summaries:
#         input: project_path+"concatenated/"+"{sample}.fastq.summary.txt"
#         output: project_path+"clipped_tags/summaries/"+"{sample}.fastq.summary.txt"
#         resources: mem_mb=lambda wildcards,  attempt: (1000*attempt)
#         params:cpu=1,
#                summaries=project_path+"clipped_tags/summaries/"
#         shell:"""
#               cp {input} {params.summaries}
# 			  """
#Below rule is to concatenate the various summary files into one, might not need
# rule cat_summary:
#         input: expand(project_path+"clipped_tags/summaries/"+"{sample}.fastq.summary.txt", sample=ids)
#         output: project_path+"clipped_tags/summaries/summaries.txt"
#         resources: mem_mb=lambda wildcards,  attempt: (1000*attempt)
#         params:cpu=1,
#         shell:"""
#               cat {input} | sort -u > {output}
#               """
              #will have to come back later to look at how to delete beginning of string
#Need a rule here to run through tagseq_clipper then fastx_clippers from tagseq_trim_launch
#rule trim_seq_fil:
#        input: project_path+"concatenated/"+"{sample}.fastq"
#        output: project_path+"clipped_tags/"+"{sample}_clip.fastq"
#        resources: mem_mb=lambda wildcards,  attempt: (1000*attempt)
#        params:cpu=1,
#               map=perl_path+"tagseq_clipper.pl",
#               seqs=project_path+"concatenated/"+"{sample}.fastq"
#        shell:"""
#              module load perl
#              module load fastx_toolkit
#              perl {params.map} {params.seqs} |,
#              fastx_clipper -a AAAAAAAA -l 20 -Q33 |,
#              fastx_clipper -a AGATCGGAAG -l 20 -Q33 |,
#              fastq_quality_filter -Q33 -q 20 -p 90 > {output}
#			  """
#This is Tim's rule to map reads to _reads_collapsed_vs_genome#mapping reads to genome

# rule map_mirna:
#     input:gen=genome,
#           index=project_path+"index/"+species+"_index_done.txt",
#           mirna=mirna_path+"{sample}.fastq.gz"
#     output:dummy=project_path+"mapping/mapping_{sample}_done.txt",
#            arf=project_path+"samples/"+"{sample}_miRNA_analysis/"+"{sample}_reads_collapsed_vs_genome.arf",
#            reads=project_path+"samples/"+"{sample}_miRNA_analysis/"+"{sample}_reads_collapsed.fa",
#     resources:mem_mb=lambda wildcards,  attempt: (2000*attempt)
#     params:cpu=1,
#            map=mirdeep_path+"mapper.pl",
#            seqs=mirna_path+"{sample}.fastq",
#            species_name=project_path+"genome/"+species,
#            id="{sample}",
#            sample_analyses=project_path+"samples/"
#     shell:"""
#           module load mirdeep2
#           zcat {input.mirna} > {params.seqs}
#           mkdir -p {params.sample_analyses}/{params.id}_miRNA_analysis
#           cd {params.sample_analyses}/{params.id}_miRNA_analysis
#           perl {params.map} {params.seqs} -e -j -l 18 -m -p {params.species_name} \
#           -h -s {params.id}_reads_collapsed.fa -t {params.id}_reads_collapsed_vs_genome.arf -v
#           touch {output}
#           """



#Now working on a rule to compare compare tags to genome
rule transcriptome:
        input:gen=genome,
              project_path+"clipped_tags/"+"{sample}_clip.fastq",
        output: #not sure what this is supposed to be
        resources: mem_mb=lambda wildcards,  attempt: (1000*attempt)
        params:cpu=1,
        shell:"""

              """
              will have to come back later to look at how to delete beginning of string



#rule stock:
#        input:
#        output:
#        resources:mem_mb=lambda wildcards,  attempt: (1000*attempt)
#        params:cpu=1
#        shell:"""
