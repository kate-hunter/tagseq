#rule stock:
#    input:
#    output:
#    resources:mem_mb=lambda wildcards,  attempt: (1000*attempt)
#    params:cpu=1
#    shell:"""
#
################################################################################USER INPUT ##################################################################
project_path="/uufs/chpc.utah.edu/common/home/kapheim-group1/miRNA_delory/maternal_mrot/"
#make sure genome extension is .fa
species="megachile_rotundata"
#where is mirdeep installed/where are the mirdeep perl scripts?
mirdeep_path="/uufs/chpc.utah.edu/sys/installdir/mirdeep2/2.0.0.8/bin/"
##what was the 3' adapter used for your microRNA library?
##adapter= this goes in the mapping stage, but adapters were already trimmed for this project (rule map_mirna)
##do you have some known microRNAs to work with?
mirna_db = "/uufs/chpc.utah.edu/common/home/kapheim-group1/mrot_maternalRNA/alignment_quantification_miRs/pres_nowhite_pres_mrot_homologs_all-in_final.fa"
##this is for a closely related species...
mirna_db_different="/uufs/chpc.utah.edu/common/home/kapheim-group1/mrot_maternalRNA/amel_novel_premirs_sans_space.fa"
##where is your snakefile?
snake_dir="/uufs/chpc.utah.edu/common/home/kapheim-group1/mrot_maternalRNA/"
##what is the name of your mature miRNA fasta file?
mature_name="megachile_sans_r_mature.fa"
##what is the name of your precursor fasta file?
precursor_name="megachile_sans_r_precursor.fa"
##what is the name of a related species/combined related species mature miRNA fasta
other_name="five_bee_sans_r_mature.fa"
##target_sequence for miRNAs
target_sequence = "/uufs/chpc.utah.edu/common/home/kapheim-group1/mirna/targets/mrot_3p500.fa"
#################################################################################END USER INPUT#############################################################
genome=project_path+"genome/"+species+".fa"
mirna_path=project_path+"sequences/"
mirna_mature=project_path+"known_miRNAs/"+mature_name
mirna_precursor=project_path+"known_miRNAs/"+precursor_name
other_mature=project_path+"known_miRNAs/"+other_name
ids, = glob_wildcards(mirna_path+"{id}.fastq.gz")
##print(ids)

##this is a snakefile to analyze micro RNA's and maybe RNA seq
rule all:
    input:project_path+"index/"+species+"_index_done.txt",
          expand(project_path+"mapping/mapping_{sample}_done.txt",sample=ids),
          expand(project_path+"mirna_found/{sample}_find_mirnas_done.txt",sample=ids),
          expand(project_path+"quantify/quantify_{sample}_done.txt",sample=ids),
          expand(project_path+"quantify/quantify_{sample}_csv_fin.txt",sample=ids),
          expand(project_path+"quantify/quantify_{sample}_filter_fin.txt",sample=ids),
          project_path+"samples/table_done.txt",
          project_path+"known_miRNAs/round_two_"+precursor_name,
          #start of mirdeep round two with combined known precursor .fa
          expand(project_path+"mirna_found/round_two_{sample}_find_mirnas_done.txt",sample=ids),
          expand(project_path+"quantify/round_two_quantify_{sample}_done.txt",sample=ids),
          expand(project_path+"quantify/round_two_quantify_{sample}_csv_fin.txt",sample=ids),
          expand(project_path+"quantify/round_two_quantify_{sample}_filter_fin.txt",sample=ids),
          project_path+"samples/round_two_table_done.txt",
          #finding target sequences
          project_path+"target_processing/miranda_done.txt",
          project_path+"target_processing/rnahybrid_done.txt"

##to do mapping we need to index the genome using "bowtie-build"
rule bowtie_build:
    input:gen=genome
    output:project_path+"index/"+species+"_index_done.txt"
    resources:mem_mb=lambda wildcards,  attempt: (1000*attempt)
    params:cpu=1,
           index_name=project_path+"genome/"+species
    shell:"""
          module load bowtie
          bowtie-build {input.gen} {params.index_name}
          touch {output}
          """
#mapping reads to genome
rule map_mirna:
    input:gen=genome,
          index=project_path+"index/"+species+"_index_done.txt",
          mirna=mirna_path+"{sample}.fastq.gz"
    output:dummy=project_path+"mapping/mapping_{sample}_done.txt",
           arf=project_path+"samples/"+"{sample}_miRNA_analysis/"+"{sample}_reads_collapsed_vs_genome.arf",
           reads=project_path+"samples/"+"{sample}_miRNA_analysis/"+"{sample}_reads_collapsed.fa",
    resources:mem_mb=lambda wildcards,  attempt: (2000*attempt)
    params:cpu=1,
           map=mirdeep_path+"mapper.pl",
           seqs=mirna_path+"{sample}.fastq",
           species_name=project_path+"genome/"+species,
           id="{sample}",
           sample_analyses=project_path+"samples/"
    shell:"""
          module load mirdeep2
          zcat {input.mirna} > {params.seqs}
          mkdir -p {params.sample_analyses}/{params.id}_miRNA_analysis
          cd {params.sample_analyses}/{params.id}_miRNA_analysis
          perl {params.map} {params.seqs} -e -j -l 18 -m -p {params.species_name} \
          -h -s {params.id}_reads_collapsed.fa -t {params.id}_reads_collapsed_vs_genome.arf -v
          touch {output}
          """
##mirdeep2 script to detect novel reads and use known reads
rule find_mirnas:
    input:mapped=project_path+"mapping/mapping_{sample}_done.txt",
          gen=genome,
          arfs=project_path+"samples/"+"{sample}_miRNA_analysis/"+"{sample}_reads_collapsed_vs_genome.arf",
          reads=project_path+"samples/"+"{sample}_miRNA_analysis/"+"{sample}_reads_collapsed.fa",
          known_mature=mirna_mature,
          known_precursor=mirna_precursor,
          other_species_mature=other_mature
    output:project_path+"mirna_found/{sample}_find_mirnas_done.txt"
    resources:mem_mb=lambda wildcards,  attempt: (4000*attempt)
    params:cpu=1,
           mirdeep=mirdeep_path+"miRDeep2.pl",
           id="{sample}",
           sample_dir="mirdeep",
           sample_analysis=project_path+"samples/"
    shell:"""
          module load bowtie
          module load mirdeep2
          cd {params.sample_analysis}/{params.id}_miRNA_analysis
          mkdir -p {params.sample_dir}
          cd {params.sample_dir}
          set e+
          perl {params.mirdeep} {input.reads} {input.gen} {input.arfs} \
          {input.known_mature} {input.other_species_mature} {input.known_precursor} 2> {params.id}_report.log
          exitcode=$?
          if [ $exitcode -eq 1 ]
          then
              exit 1
          else
              touch {output}
              exit 0
          fi
          """


#you get the quantified html tables here but snakemake exits non-0 try using the set e+... to deal with this
rule quantify:
    input:dummy=project_path+"mirna_found/{sample}_find_mirnas_done.txt",
          seqs=project_path+"samples/"+"{sample}_miRNA_analysis/"+"{sample}_reads_collapsed.fa"
    output:project_path+"quantify/quantify_{sample}_done.txt"
    resources:mem_mb=lambda wildcards,  attempt: (8000*attempt)
    params:cpu=1,
           quantify=mirdeep_path+"quantifier.pl",
           dir_name=project_path+"samples"+"/{sample}_miRNA_analysis/mirdeep",
           quant="quantify"
    shell:"""
          #module load mirdeep2
          #cd {params.dir_name}
          #export PRECURSOR=`ls mirna_results*/novel_pres*_to_na.fa`
          #export MATURE=`ls mirna_results*/novel_mature_*_to_na.fa`
          #export STAR=`ls mirna_results*/novel_star_*_to_na.fa`
          #perl {params.quantify} -p $PRECURSOR -m $MATURE -r {input.seqs} -s $STAR
          touch {output}
          """

#this takes the .html quantifications of your reads and turns them into tables for each individual
rule make_quant_csvs:
    input:py_script="make_mirdeep_tables.py",
          quant_dummy=project_path+"quantify/quantify_{sample}_done.txt"
    output:project_path+"quantify/quantify_{sample}_csv_fin.txt"
    resources:mem_mb=lambda wildcards,  attempt: (1000*attempt)
    params:cpu=1,
           prefix_name=project_path+"samples/{sample}_miRNA_analysis/mirdeep"
    shell:"""
          module use $HOME/MyModules
          module load miniconda3/latest
          export QUANT_HTML=`ls {params.prefix_name}/result*html`
          python {input.py_script} $QUANT_HTML {params.prefix_name}
          touch {output}
          """

#takes the csvs generated from html and
rule filtered_csv:
    input:table_dummy=project_path+"quantify/quantify_{sample}_csv_fin.txt"
    output:project_path+"quantify/quantify_{sample}_filter_fin.txt"
    resources:mem_mb=lambda wildcards,  attempt: (1000*attempt)
    params:cpu=1,
           prefix_name=project_path+"samples/{sample}_miRNA_analysis/mirdeep",
           id="{sample}"
    shell:"""
          export CSV_QUANT=`ls {params.prefix_name}/miRNA_criteria.csv`
          module load R
          Rscript filter_quant_csv.R $CSV_QUANT {params.prefix_name}/ {params.id}
          touch {output}
          """

#combine all filtered csvs into single csv
#then grab filter so that there is only one copy of any row that has the same contig_start_stop_strand id
#then check for potentially overlapping miRNA sequences in the genome
rule make_count_table:
    input:expand(project_path+"quantify/quantify_{sample}_filter_fin.txt",sample=ids)
    output:project_path+"samples/table_done.txt"
    resources:mem_mb=lambda wildcards,  attempt: (1000*attempt)
    params:cpu=1,
           csvs_path=project_path+"samples/",
           csv_out_path=project_path+"samples/"
    shell:"""
          FILTERED_CSVS=`ls {params.csvs_path}*miRNA_analysis/mirdeep/filtered_ids.csv`
          cat $FILTERED_CSVS > {params.csv_out_path}combined.csv
          module load R
          Rscript make_table.R {params.csv_out_path}combined.csv {params.csv_out_path}
          touch {output}
          """

#to deal with the overlapping precursors, we are going to "bootstrap" and add the filtered precursors to the known precursor .fa
rule new_known:
    input:known_precursor=mirna_precursor,
          filtered_done=project_path+"samples/table_done.txt"
    output:project_path+"known_miRNAs/round_two_"+precursor_name
    resources:mem_mb=lambda wildcards,  attempt: (1000*attempt)
    params:cpu=1,
           table_path=project_path+"samples",
           filtered_pre_fa=project_path+"known_miRNAs/filtered_precursors.fa"
    shell:"""
          module load R
          Rscript make_new_fa.R {params.table_path}/unique_miRNA_locs.csv {params.filtered_pre_fa}
          cat {input.known_precursor} {params.filtered_pre_fa} > {output}
          """
#this takes a an .fa of known precurors from the first round of mirdeep and is combined
#with filtered novel precursors to mirdeep determine the most likely position of the mature consensus miRNAs
#to avoid having to collapse or pick which overlapping precursor is correct for a consesnsus sequence.
rule find_mirnas_round_two:
    input:mapped=project_path+"mapping/mapping_{sample}_done.txt",
          gen=genome,
          arfs=project_path+"samples/"+"{sample}_miRNA_analysis/"+"{sample}_reads_collapsed_vs_genome.arf",
          reads=project_path+"samples/"+"{sample}_miRNA_analysis/"+"{sample}_reads_collapsed.fa",
          known_mature=mirna_mature,
          #this known precursor is fa is the difference between the round one and round 2 run
          known_precursor=project_path+"known_miRNAs/round_two_"+precursor_name,
          other_species_mature=other_mature
    output:project_path+"mirna_found/round_two_{sample}_find_mirnas_done.txt"
    resources:mem_mb=lambda wildcards,  attempt: (4000*attempt)
    params:cpu=1,
           mirdeep=mirdeep_path+"miRDeep2.pl",
           id="{sample}",
           sample_dir="mirdeep",
           sample_analysis=project_path+"samples/"
    shell:"""
          module load bowtie
          module load mirdeep2
          cd {params.sample_analysis}/{params.id}_miRNA_analysis
          mkdir -p {params.sample_dir}_round_two
          cd {params.sample_dir}_round_two
          set e+
          perl {params.mirdeep} {input.reads} {input.gen} {input.arfs} \
          {input.known_mature} {input.other_species_mature} {input.known_precursor} 2> {params.id}_report.log
          exitcode=$?
          if [ $exitcode -eq 1 ]
          then
              exit 1
          else
              touch {output}
              exit 0
          fi
          """


rule quantify_round_two:
    input:dummy=project_path+"mirna_found/{sample}_find_mirnas_done.txt",
          seqs=project_path+"samples/"+"{sample}_miRNA_analysis/"+"{sample}_reads_collapsed.fa"
    output:project_path+"quantify/round_two_quantify_{sample}_done.txt"
    resources:mem_mb=lambda wildcards,  attempt: (8000*attempt)
    params:cpu=1,
           quantify=mirdeep_path+"quantifier.pl",
           dir_name=project_path+"samples"+"/{sample}_miRNA_analysis/mirdeep_round_two",
           quant="quantify"
    shell:"""
          module load mirdeep2
          cd {params.dir_name}
          export PRECURSOR=`ls mirna_results*/novel_pres*_to_na.fa`
          export MATURE=`ls mirna_results*/novel_mature_*_to_na.fa`
          export STAR=`ls mirna_results*/novel_star_*_to_na.fa`
          perl {params.quantify} -p $PRECURSOR -m $MATURE -r {input.seqs} -s $STAR
          touch {output}
          """

#for the round two run, we are only interested in collecting data from the known miRs table of the results html
#this table inlcudes discovered precursors that passed filtering criteria in round one of mirdeep
#this was done in the hopes that mature consensus sequences would get mapped to the stronger of two or three candidate precursors
#as there were overlapping unkown precursors in many of the samples, but they often didn't both have significant rand fold values
rule make_quant_csvs_round_two:
    input:py_script="make_mirdeep_tables_round_two.py",
          quant_dummy=project_path+"quantify/quantify_{sample}_done.txt"
    output:project_path+"quantify/round_two_quantify_{sample}_csv_fin.txt"
    resources:mem_mb=lambda wildcards,  attempt: (1000*attempt)
    params:cpu=1,
           prefix_name=project_path+"samples/{sample}_miRNA_analysis/mirdeep_round_two"
    shell:"""
          module use $HOME/MyModules
          module load miniconda3/latest
          export QUANT_HTML=`ls {params.prefix_name}/result*html`
          python {input.py_script} $QUANT_HTML {params.prefix_name}
          touch {output}
          """

rule filtered_csv_round_two:
    input:table_dummy=project_path+"quantify/quantify_{sample}_csv_fin.txt"
    output:project_path+"quantify/round_two_quantify_{sample}_filter_fin.txt"
    resources:mem_mb=lambda wildcards,  attempt: (1000*attempt)
    params:cpu=1,
           prefix_name=project_path+"samples/{sample}_miRNA_analysis/mirdeep_round_two",
           id="{sample}"
    shell:"""
          export CSV_QUANT=`ls {params.prefix_name}/miRNA_criteria.csv`
          module load R
          Rscript filter_quant_csv.R $CSV_QUANT {params.prefix_name}/ {params.id}
          touch {output}
          """

rule make_count_table_round_two:
    input:expand(project_path+"quantify/quantify_{sample}_filter_fin.txt",sample=ids)
    output:project_path+"samples/round_two_table_done.txt"
    resources:mem_mb=lambda wildcards,  attempt: (1000*attempt)
    params:cpu=1,
           csvs_path=project_path+"samples/",
           csv_out_path=project_path+"samples/"
    shell:"""
          FILTERED_CSVS=`ls {params.csvs_path}*miRNA_analysis/mirdeep_round_two/filtered_ids.csv`
          cat $FILTERED_CSVS > {params.csv_out_path}round_two_combined.csv
          module load R
          Rscript make_table.R {params.csv_out_path}round_two_combined.csv {params.csv_out_path}round_two_
          touch {output}
          """

#ultimately we want a rule in between here that will take the output of make_count_table_round_two
#and make the maternal_mature.fa, which is a file of the unique mature sequences across all samples that passed filtering both rounds
#run miranda for samples
rule run_miranda:
    input:dependency=project_path+"samples/round_two_table_done.txt",
          mature_final="/uufs/chpc.utah.edu/common/home/kapheim-group1/miRNA_delory/maternal_mrot/target_processing/maternal_mature.fa",
          target=target_sequence
    output:project_path+"target_processing/miranda_done.txt"
    resources:mem_mb=lambda wildcards,  attempt: (9000*attempt)
    params:cpu=1,
           miranda_path=project_path+"target_processing/"
    shell:"""
          cd {params.miranda_path}
          module load miranda/3.3a
          miranda {input.mature_final} {input.target} -en -20 -sc 140 -strict -out miranda_out
          touch {output}
          """
#run rnahybrid same mature sequence file -q and target file -t as used in miranda
rule rnahybrid:
    input:dependency=project_path+"samples/round_two_table_done.txt",
          target=target_sequence,
          mature_final="/uufs/chpc.utah.edu/common/home/kapheim-group1/miRNA_delory/maternal_mrot/target_processing/maternal_mature.fa"
    output:project_path+"target_processing/rnahybrid_done.txt"
    resources:mem_mb=lambda wildcards,  attempt: (9000*attempt)
    params:cpu=1,
           rnahybrid_path=project_path+"target_processing/"
    shell:"""
          cd {params.rnahybrid_path}
          module load rnahybrid
          RNAhybrid -e -20 -c -s 3utr_fly -t {input.target}  -q {input.mature_final}  > rnahybrid_out
          touch {output}
          """
